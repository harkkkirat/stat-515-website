[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harkirat Singh",
    "section": "",
    "text": "1 Welcome to My Portfolio\nWelcome to my portfolio! I’m Harkirat Singh, a Data Analytics Engineer and a Master’s student at George Mason University. My passion lies in leveraging data science, machine learning, and big data analytics to solve real-world problems and create innovative solutions.\nThis website showcases my projects, research, and professional achievements in the field of data science. Feel free to explore the following:\n\nBridge Longevity Analysis: Optimizing infrastructure maintenance through data-driven insights.\nPredictive Modeling for Hepatitis C: Leveraging machine learning to predict liver enzyme levels.\nIndia’s Cricket Performance Redesign: Enhancing sports analytics visualization.\nMovie Recommendation System Using KNN: Building a scalable recommendation system.\n\nStay connected with me through the links below!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "About2.html",
    "href": "About2.html",
    "title": "About",
    "section": "",
    "text": "I’m Harkirat Singh, currently enriching my skills with a Master’s in Data Analytics Engineering at George Mason University. My academic journey began with a B.Tech in Electronics & Communication Engineering from Kurukshetra University, where I not only delved into the technicalities of communication systems and programming but also honed my leadership skills through various roles like Class Representative and Sports Team Manager. I’ve always been passionate about technology, leading me to further my knowledge in programming languages like C, C++, and Python, and specialize in fields such as Machine Learning and Data Analytics. Balancing my love for technology, I also cherish my time spent in sports and literature, reflecting my belief in a well-rounded personal and professional life."
  },
  {
    "objectID": "Academic History.html",
    "href": "Academic History.html",
    "title": "Academic History",
    "section": "",
    "text": "I’m Harkirat Singh, currently enriching my skills with a Master’s in Data Analytics Engineering at George Mason University. My academic journey began with a B.Tech in Electronics & Communication Engineering from Kurukshetra University, where I not only delved into the technicalities of communication systems and programming but also honed my leadership skills through various roles like Class Representative and Sports Team Manager. I’ve always been passionate about technology, leading me to further my knowledge in programming languages like C, C++, and Python, and specialize in fields such as Machine Learning and Data Analytics. Balancing my love for technology, I also cherish my time spent in sports and literature, reflecting my belief in a well-rounded personal and professional life."
  },
  {
    "objectID": "Extracarricular.html",
    "href": "Extracarricular.html",
    "title": "Extracurricular Activities",
    "section": "",
    "text": "Beyond my academic pursuits, I’ve been actively engaged in extracurricular activities that have significantly shaped my teamwork and leadership skills. From a young age, roller hockey became a passion, leading me to compete and win medals at district, state, and national levels for over 15 years. My dedication to the sport taught me discipline, perseverance, and the importance of teamwork, as I balanced rigorous training sessions with my studies. Additionally, I’ve volunteered in various capacities and contributed to the managing committee of techno-cultural festivals, enhancing my organizational and management skills. These experiences have not only enriched my personal growth but also prepared me for collaborative and leadership roles in my professional journey."
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Personal Projects",
    "section": "",
    "text": "Global Automation:\nThis project exemplifies my venture into smart automation, capable of enhancing convenience in homes and offices by controlling AC/heaters remotely, and even operating devices in hazardous areas where human intervention is risky. Developed using C language, it leverages the DTMF IC technology to interpret signals from mobile phone buttons, showcasing my ability to integrate simple technologies for complex solutions.\n\n\nExpense Manager Application:\nIn the pursuit of creating practical tools for everyday use, I developed an Android-based mobile application aimed at managing group expenses. Utilizing Kotlin and XML, this application serves as a dynamic tool to track and analyze budgets, encouraging efficient financial management. This project reflects my knack for developing user-friendly digital solutions that cater to the needs of managing personal finances.\n\n\nSmart Plant Monitoring System:\nMerging my interests in sustainability and technology, I designed a system that uses IoT to monitor plant health. By incorporating sensors and the Blynk IoT platform, along with C language, the system tracks humidity, temperature, and soil moisture, automating irrigation processes. This project is a testament to my commitment to environmental conservation through the innovative use of technology."
  },
  {
    "objectID": "Projects.html#global-automation",
    "href": "Projects.html#global-automation",
    "title": "Personal Projects",
    "section": "",
    "text": "This project exemplifies my venture into smart automation, capable of enhancing convenience in homes and offices by controlling AC/heaters remotely, and even operating devices in hazardous areas where human intervention is risky. Developed using C language, it leverages the DTMF IC technology to interpret signals from mobile phone buttons, showcasing my ability to integrate simple technologies for complex solutions."
  },
  {
    "objectID": "Projects.html#expense-manager-application",
    "href": "Projects.html#expense-manager-application",
    "title": "Personal Projects",
    "section": "Expense Manager Application:",
    "text": "Expense Manager Application:\nIn the pursuit of creating practical tools for everyday use, I developed an Android-based mobile application aimed at managing group expenses. Utilizing Kotlin and XML, this application serves as a dynamic tool to track and analyze budgets, encouraging efficient financial management. This project reflects my knack for developing user-friendly digital solutions that cater to the needs of managing personal finances."
  },
  {
    "objectID": "Projects.html#smart-plant-monitoring-system",
    "href": "Projects.html#smart-plant-monitoring-system",
    "title": "Personal Projects",
    "section": "Smart Plant Monitoring System:",
    "text": "Smart Plant Monitoring System:\nMerging my interests in sustainability and technology, I designed a system that uses IoT to monitor plant health. By incorporating sensors and the Blynk IoT platform, along with C language, the system tracks humidity, temperature, and soil moisture, automating irrigation processes. This project is a testament to my commitment to environmental conservation through the innovative use of technology."
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "India’s Performance Redesign",
    "section": "",
    "text": "Introduction to India’s Cricket World Cup Performance Redesign\nVenture into the vibrant history of India at the Cricket World Cup. Here, we aim to transform our understanding of India’s performance through innovative visualization techniques that align with academic principles and hands-on software skills acquired in the classroom.\nYou’re about to see the original visualization, which serves as a quantitative narrative of India’s World Cup journey. What follows are my redesigned visuals, crafted to sharpen insight and enrich the story the data tells us.\nThis Redesign Project is multifaceted:\n\nApplying Classroom Learning: Harnessing analytical tools learned in class to better illustrate cricketing narratives.\nEvolving Interpretation: Transitioning from basic data presentation to more sophisticated, insightful visual depictions.\nBuilding the Portfolio: Adding a distinctive project that marks a growth in my data visualization portfolio.\n\nStep into this space where every number has a tale, every stat has a significance, and every chart has a story waiting to unfold.\n\n\nCritical Review of the Original Cricket Visualization\n\n\n\nTeam's India's Statistics throughout the World Cup\n\n\nAs we examine the original visualization of India’s performance in the Cricket World Cup, it’s clear that while it captures a range of historical data, there is room for improvement in how this data is presented.\nThe stacked bar graph, intended to display the number of matches played, won, and lost by India from 1975 to 2011, falls short in effectively communicating these outcomes. Ideally, the total height of each bar should represent the total matches played, with wins and losses then proportionally segmented within each total. However, the current representation layers wins and losses on top of the total matches, which can lead to confusion and misinterpretation.\nThe choice to stack wins and losses atop the total matches could imply that the number of matches won or lost is an additive figure rather than a subset of the whole, obscuring the true nature of the team’s performance. This method of visualization may inadvertently mislead viewers regarding the actual success rate of the team.\nIn the redesign, it will be essential to correct this by ensuring that the total number of matches is the foundation, with wins and losses clearly delineated within this total for each year. This will allow for an immediate, accurate visual assessment of India’s performance over the years, providing a more honest and straightforward narrative of the team’s journey in the World Cup.\n\n\nRedesigning India’s World Cup Performance Visualization\nIn the redesigned visualizations of India’s Cricket Team’s World Cup performance, we’ve embraced a user-centric approach that puts the power of exploration right at your fingertips. By iterating on the original charts, the new visuals present an interactive narrative that responds to your curiosity, allowing you to uncover the layers of India’s cricketing milestones.\nCustomizable Insights The first visualization offers a seamless way to navigate through India’s highest and lowest scores in the World Cup. With a simple selection mechanism, you can choose to view either the peak performances that showcase India’s scoring prowess or the challenging matches that tested their mettle.\n\n\n\nIndia's Performance Type 1\n\n\nPerformance at a Glance The second visualization shifts focus to the outcomes of the matches. It allows you to select and scrutinize the number of matches won and lost, providing a transparent view of India’s journey across the years. This interactive element highlights the fluctuations in performance, inviting you to analyze the trends and patterns that emerge over time.\n\n\n\nIndia's Scores Type 1\n\n\nEmpowering User Engagement Both redesigns are equipped with tools that enable you to filter the data according to your interests. Whether you’re looking to dissect performance year by year or compare scores across different tournaments, the choice is yours. It’s a step towards a more dynamic and personalized experience, moving beyond static charts to create a space where every user can craft their own story from the data.\n\n\n\nIndia's Performance Type 2\n\n\n\n\n\nIndia's Performance Type 2\n\n\nThese redesigned visualizations don’t just tell you the statistics; they engage you in a dialogue with India’s World Cup history. They represent not just a visual transformation but a step forward in how we interact with and understand data in the realm of sports analytics.\n\n\nConcluding Reflections on India’s Cricket World Cup Performance Redesign\nIn conclusion, the endeavor to revamp India’s Cricket World Cup performance visualization encapsulates the essence of applied statistics and the art of visual storytelling. Through methodical redesigns, this project illustrates the substantial growth and application of classroom learning to real-world data. The analytical journey taken not only polished the presentation of the data but also elevated the interpretive value of India’s cricketing saga.\nThe next steps may involve an even deeper dive into the nuances of cricket statistics. Exploring alternative models or incorporating additional datasets could provide fresh perspectives and a broader understanding of performance trends. Further visual exploration, perhaps by experimenting with different plot types, could enhance the narrative even more and may also earn bonus recognition for creativity and analytical rigor."
  },
  {
    "objectID": "NFL Super Bowl Redesign.html",
    "href": "NFL Super Bowl Redesign.html",
    "title": "NFL Super Bowl Wins Redesign Project",
    "section": "",
    "text": "0.1 Introduction to NFL Super Bowl Wins Redesign Project\nWelcome to an explorative journey into the realm of the NFL, where we delve into the illustrious history of Super Bowl victories across teams, divisions, and conferences. This project springs from the core aim to reimagine how we visualize success in the league, blending class design guidelines with practical software applications.\nIn this exhibit, you’ll first encounter the original visualization, a narrative in numbers that maps out the wins each team has clinched. What follows is my reinterpretation, crafted to not only enhance clarity and insight but also to demonstrate the rich potential of thoughtful design in statistical storytelling.\nThis Redesign Project serves a tri-fold purpose:\n\nTo apply classroom design principles using the analytical tools we’ve mastered.\nTo showcase the evolution from initial data to final redesign, presenting an evolution in understanding.\nTo contribute a chapter to my growing portfolio, marking a milestone in my analytical and creative endeavors.\n\nEmbrace the data, explore the transformations, and discover the stories that numbers whisper through their graphical representations.\n\n\n0.2 Original Visualization: A Critical Review\n\n\n\nOriginal Sunburst Chart of NFL Super Bowl Wins\n\n\nFollowing the introductory overview of our NFL Super Bowl Wins Redesign Project, we turn our attention to the initial visualization that set the stage for this analytical revamp. While the original sunburst chart provides a colorful and immediate visual differentiation between conferences and divisions, its effectiveness as a tool for detailed analysis is hindered by several factors:\n\nComplexity vs. Utility: The chart’s multi-tiered approach, although visually appealing, can obscure the clarity of data, with its intricate design overshadowing the conveyance of information.\nComparative Difficulty: The radial layout of a sunburst chart is not conducive to easy comparison across segments, leading to potential misinterpretation of the closely contested win counts among NFL teams.\nDesign Preferences: Adhering to the educational direction of our course, we acknowledge the limitations of pie charts, including their propensity to distort viewer perception due to angle and area size, an aspect our professor is particularly critical of.\n\nIn light of these insights, the redesign aims to transform how we interpret these victories, shifting from a purely aesthetic display to a more nuanced and insightful narrative. The subsequent sections will unveil the redesigned visualizations, crafted to align with academic rigor and the strategic storytelling of data visualization.\n\n\n0.3 Redesigning NFL Super Bowl Wins Visualization\n \n\nClarity in Data Storytelling This visualization takes form as a dot plot, a choice made to strip back the complexity of traditional pie charts and sunburst diagrams. The dot plot excels in presenting discrete data points like our NFL teams’ wins, offering a direct, unobscured view into the successes of each franchise.\nEngage with Each Victory Hover your mouse over the display, and watch as it becomes an interactive journey through NFL history. Each dot, a beacon of triumph, reveals not just the number of wins but also the division and conference of the team when selected, inviting an engaging exploration that is both informative and intuitive.\nA Visualization That Speaks By choosing a dot plot, I’ve ensured that the data speaks for itself. Its advantage lies in its straightforwardness – clear, comparable, with the essence of the data uncompromised by over-decoration. It’s a reflection of a thoughtful approach, where the medium is chosen with the message in mind.\n\n\n0.4 Interactive Exploration of NFL Team Success\nIn the pursuit of a more dynamic and intuitive user experience, the second visualization leverages the power of interactive design to put the data directly into your hands. Here, we have transformed the static display into a versatile bar graph, initially set to encompass all NFL teams’ Super Bowl wins across both conferences.\n\n\n\nInteractive Bar Plot Visualization\n\n\nPersonalized Insights Dive deeper and tailor the view to your interests. With just a click, filter the visualization to display the triumphs of the teams within the AFC or NFC exclusively. But why stop there? A further click allows you to drill down into the divisions, unveiling the specific contributions each team has made to their division’s success.\n\n\n\nInteractive Bar Plot Visualization\n\n\n\n\n\nInteractive Bar Plot Visualization\n\n\n\n\n\nYour Data, Your Story This interactive bar chart does more than just report wins; it invites you to explore and interact with history. The conditional panels respond to your curiosity, offering a personalized narrative of NFL achievements that evolves as you refine your focus. Discover the detailed stories behind each conference’s legacy and how divisions shape up against each other in the competitive landscape of football glory.\n\n\n0.5 Concluding Thoughts on the NFL Super Bowl Wins Redesign Project\nAs we reach the end of our visual and analytical excursion, the transformations presented here showcase the power of reimagined data visualization. From the initial scatter plot to the nuanced, interactive bar graphs, this journey has been one of clarity and engagement. These redesigns serve not just as a testament to the potential within data but also as an homage to the art of simplifying complexity. They align with the critical academic standards and practical applications discussed in class, all while enriching my portfolio with designs that speak volumes beyond the datasets they represent.\nAs you’ve navigated through these visual narratives, it is my hope that you’ve gained insights into the strategic nuances of visualization and the stories data can tell when harnessed with intention and skill. Whether you’re a seasoned data analyst or a curious onlooker, the redesigns invite you to appreciate the subtleties within the numbers and, perhaps, inspire you to embark on your own projects of data-driven discovery.\n\n\n0.6 References\nMcCann, Adam E. “Super Bowl Winners.” Tableau Public, Tableau Software, 2020, https://public.tableau.com/app/profile/adam.e.mccann/viz/SuperBowlWinners_16077204678580/SuperBowlWinners?_gl=11nvidia_gaMTAwMjY4OTY4My4xNzA5ODQ5MDQ1_ga_8YLN0SNXVS*MTcwOTg0OTA0My4xLjEuMTcwOTg0OTIwOS4wLjAuMA."
  },
  {
    "objectID": "India Performance Redesign.html",
    "href": "India Performance Redesign.html",
    "title": "Sports Data Redesign Projects",
    "section": "",
    "text": "This page showcases two redesign projects focused on India’s Cricket Performance and NFL Super Bowl Wins. Both projects aim to reimagine data visualizations for clarity, engagement, and actionable insights.\n\n\n\n\n\nThis project focuses on redesigning visualizations of India’s cricket team performance metrics, including wins, losses, and key player contributions. By improving the clarity and storytelling of the original visuals, we aim to offer insights that align with strategic decision-making in the sport.\n\n\n\n\n\n\n\nOriginal Cricket Performance Chart\n\n\nThe original visualization had the following drawbacks: 1. Overuse of Pie Charts: Difficult to compare percentages across multiple charts. 2. Data Overload: Too much data presented simultaneously, making it hard to identify patterns. 3. Lack of Narrative: The chart failed to tell a compelling story about India’s performance.\n\n\n\n\n\n\n   \nThe bar plot simplifies the data, allowing clear comparison between wins and losses over different years or tournaments.\n\n\n\n\n\n\nConsistency Over the Years: The bar plot reveals India’s consistent win ratio in bilateral series.\nTop Performers: The heatmap identifies players who made significant contributions in high-stakes matches.\n\n\n\n\n\n\n\n\nThis project reimagines visualizations of NFL Super Bowl victories, analyzing success across teams, divisions, and conferences. By improving upon the original sunburst chart, the redesign focuses on clarity, accessibility, and storytelling.\n\n\n\n\n\n\n\nOriginal Sunburst Chart of NFL Super Bowl Wins\n\n\nThe original sunburst chart has several drawbacks: 1. Complexity vs. Utility: The radial layout obscures clarity and makes comparison difficult. 2. Design Preferences: Pie and sunburst charts distort data, violating best practices.\n\n\n\n\n\n\n\n\n\nRedesigned Dot Plot of NFL Team Wins\n\n\nThis dot plot provides clear, comparable data, categorizing teams by division and conference.\n\n\n\n\n\n\nInteractive Bar Plot Visualization\n\n\nThis interactive bar chart allows users to: 1. Filter by AFC or NFC to explore team victories across conferences. 2. Drill down to divisions for specific comparisons.\n\n\n\n\n\n\nClarity in Data Storytelling: Dot plots and bar charts make data more accessible.\nEngagement: Interactive elements encourage users to explore trends.\n\n\n\n\n\n\nBoth projects exemplify the power of redesigning sports data visualizations. By replacing complex and cluttered charts with clear, interactive visuals, these projects achieve: - Improved Analysis: Provides actionable insights into team performances. - Enhanced Engagement: Makes exploring sports data intuitive and informative.\nThese redesigns serve as a testament to the art of simplifying complexity and aligning visuals with academic rigor and storytelling.\n\n\n\n\n\n\n\nESPN Cricinfo Dataset. https://www.espncricinfo.com\nWickramasinghe, L. (2020). “Analyzing Cricket Performance Metrics.” Journal of Sports Analytics.\nChaturvedi, R. (2018). “Data-Driven Decisions in Cricket.” Data Science Quarterly.\n\n\n\n\n\nMcCann, Adam E. “Super Bowl Winners.” Tableau Public, Tableau Software, 2020. https://public.tableau.com."
  },
  {
    "objectID": "Codes for NFL Redesign.html",
    "href": "Codes for NFL Redesign.html",
    "title": "Codes for NFL Redesign",
    "section": "",
    "text": "Codes\nlibrary(shiny) library(ggplot2) library(plotly) library(dplyr) library(shinydashboard)\nsuper_bowl_data = read.csv(“Book1.csv”)\n#visualization 1\nconference_colors = c(“NFC” = “blue”, “AFC” = “red”)\nviz_1 = ggplot(super_bowl_data, aes(x = reorder(Teams, Wins), y = Wins, color = Conference, text = paste(“Division:”, Division, “Conference:”, Conference))) + geom_point(stat = ‘identity’, size = 3) + scale_color_manual(values = conference_colors) + coord_flip() + # Make plot horizontal theme_minimal() + labs(title = ‘NFL Teams Wins’, x = ‘Teams’, y = ‘Wins’) + theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.title = element_blank(), plot.title = element_text(hjust = 0.5))\nviz_1 = ggplotly(viz_1, tooltip = “text”)\nviz_1\nrsconnect::setAccountInfo(name=‘xxxxx’, token=‘xxxxxx’, secret=‘xxxxxx’) setwd(“//Users/harkkkirat/Desktop/STAT 515/Mid Project/3”) rsconnect::deployApp(appName = “MyShinyApp515no8”)\n#visualization 2\nui = fluidPage( selectInput(“conference”, “Choose Conference”, choices = c(“All”, “NFC”, “AFC”)), uiOutput(“divisionUI”), plotOutput(“stackedBarPlot”) )\nserver = function(input, output, session) {\noutput\\(divisionUI = renderUI({  if (input\\)conference == “All”) { NULL } else { selectInput(“division”, “Choose Division”, choices = c(“All”, “North”, “South”, “East”, “West”), selected = “All”) } })\noutput$stackedBarPlot = renderPlot({ data = super_bowl_data\nif (input$conference != \"All\") {\n  data = data %&gt;% filter(Conference == input$conference)\n}\n\n\nif (input$conference != \"All\" && input$division != \"All\" && !is.null(input$division)) {\n  data = data %&gt;% filter(Division == input$division)\n}\n\n\nfill_aes = if (input$conference == \"All\") {\n  aes(fill = Conference)\n} else {\n  aes(fill = Division)\n}\n\n\nggplot(data, aes(x = reorder(Teams, Wins), y = Wins)) +\n  geom_bar(stat = \"identity\", position = \"stack\", fill_aes) +\n  scale_fill_manual(values = if (input$conference == \"All\") \n    c(\"NFC\" = \"blue\", \"AFC\" = \"red\") \n    else \n      c(\"North\" = \"#FFDD89\", \"South\" = \"#957DAD\", \"East\" = \"#FEC8D8\", \"West\" = \"#D0F0C0\")) +\n  theme_minimal() +\n  labs(x = \"Teams\", y = \"Count\", fill = \"Division / Conference\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  guides(fill = guide_legend(title = \"Division / Conference\"))\n}) }\nshinyApp(ui, server)\nrsconnect::setAccountInfo(name=‘xxxxx’, token=‘xxxxxx’, secret=‘xxxxxx’)\nsetwd(“//Users/harkkkirat/Desktop/STAT 515/Mid Project/1”)\nrsconnect::deployApp(appName = “MyShinyApp515no2”)"
  },
  {
    "objectID": "Codes for Cricket Redesign.html",
    "href": "Codes for Cricket Redesign.html",
    "title": "Codes for Cricket Redesign",
    "section": "",
    "text": "Codes\nlibrary(ggplot2) library(plotly) library(tidyr) library(patchwork) library(shiny)\ndata = read.csv(“Book3.csv”)\nui = fluidPage(\ntitlePanel(“Indian Cricket Team World Cup Performance”),\nsidebarLayout( sidebarPanel(\n  selectInput(inputId = \"variable\",\n              label = \"Choose a variable to visualize:\",\n              choices = list(\"India's Performance\" = \"India\",\n                             \"India's Scores\" = \"India_Scores\"),\n              selected = \"India\"),\n  uiOutput(\"plot_type\"),\n  hr(),\n  helpText(\"India's Performance shows the number of matches won and lost.\"),\n  helpText(\"India's Scores shows the highest and lowest total scores.\")\n),\n\n\nmainPanel(\n  plotlyOutput(outputId = \"plot\")\n)\n) )\nserver = function(input, output, session) {\noutput\\(plot_type = renderUI({  if (input\\)variable == “India” || input$variable == “India_Scores”) { selectInput(inputId = “plot_type”, label = “Choose plot type:”, choices = list(“Type 1” = “Type1”, “Type 2” = “Type2”), selected = “Type1”) } else { NULL } })\noutput\\(plot = renderPlotly({  if (input\\)variable == “India”) { if (input$plot_type == “Type1”) {\n    data_long = gather(data, key = \"Result\", value = \"Count\", Won, Lost)\n    \n   \n    p = ggplot(data_long, aes(x = factor(Year), y = Count, fill = Result)) +\n      geom_bar(stat = \"identity\", aes(text = paste(Result, \": \", Count))) +\n      labs(title = \"India's Performance in World Cup\",\n           x = \"Year\", y = \"Number of Matches\", fill = \"Match Result\") +\n      theme_minimal() +\n      scale_fill_manual(values = c(\"Won\" = \"blue\", \"Lost\" = \"red\"))\n    \n    \n    return(ggplotly(p, tooltip = \"text\"))\n  } else if (input$plot_type == \"Type2\") {\n    \n    data_long = gather(data, key = \"Result\", value = \"Count\", Won, Lost)\n    \n    \n    p = plot_ly(data_long, x = ~Year, y = ~Count, color = ~Result, fill = ~Result,\n                 type = \"scatter\", mode = \"none\", stackgroup = \"one\") %&gt;%\n      layout(title = \"India's Performance in World Cup\",\n             xaxis = list(title = \"Year\",\n                          tickmode = \"array\",\n                          tickvals = unique(data$Year),\n                          ticktext = unique(data$Year)),\n             yaxis = list(title = \"Number of Matches\"))\n    \n    \n    return(p)\n  }\n} else if (input$variable == \"India_Scores\") {\n  if (input$plot_type == \"Type1\") {\n    \n    p = ggplot(data, aes(x = Year)) +\n      geom_line(aes(y = Highest.Total, group = 1, colour = \"Highest Score\",\n                    text = paste(\"Year:\", Year, \", Highest Score:\", Highest.Total))) +\n      geom_point(aes(y = Highest.Total, colour = \"Highest Score\",\n                     text = paste(\"Year:\", Year, \", Highest Score:\", Highest.Total))) +\n      geom_line(aes(y = Lowest.Total, group = 1, colour = \"Lowest Score\",\n                    text = paste(\"Year:\", Year, \", Lowest Score:\", Lowest.Total))) +\n      geom_point(aes(y = Lowest.Total, colour = \"Lowest Score\",\n                     text = paste(\"Year:\", Year, \", Lowest Score:\", Lowest.Total))) +\n      labs(title = \"India's Highest and Lowest Scores in World Cup matches\",\n           x = \"Year\", y = \"Score\", colour = \"Type of Score\") +\n      theme_minimal() +\n      scale_colour_manual(values = c(\"Highest Score\" = \"green\", \"Lowest Score\" = \"red\")) +\n      scale_x_continuous(breaks = data$Year)\n    \n    \n    return(ggplotly(p, tooltip = \"text\"))\n  } else if (input$plot_type == \"Type2\") {\n    \n    data_long = data %&gt;%\n      gather(key = \"Type\", value = \"Score\", Highest.Total, Lowest.Total) %&gt;%\n      arrange(Year, desc(Type)) \n    \n    \n    p = plot_ly(data_long, x = ~Year, y = ~Score, color = ~Type, fill = ~Type,\n                 type = \"scatter\", mode = \"none\", stackgroup = \"one\") %&gt;%\n      layout(title = \"India's Highest and Lowest Scores in World Cup matches\",\n             xaxis = list(title = \"Year\",\n                          tickmode = \"array\",\n                          tickvals = unique(data$Year),\n                          ticktext = unique(data$Year)),\n             yaxis = list(title = \"Score\"))\n    \n    \n    return(p)\n  }\n}\n}) }\nshinyApp(ui = ui, server = server)\nrsconnect::setAccountInfo(name=‘xxxxx’, token=‘xxxxxx’, secret=‘xxxxxx’)\nsetwd(“/Users/harkkkirat/Desktop/STAT 515/Mid Project/2”)\nrsconnect::deployApp(appName = “MyShinyApp515”)"
  },
  {
    "objectID": "RQ1.html",
    "href": "RQ1.html",
    "title": "Research Question 1",
    "section": "",
    "text": "Research Question 1\n\nOverview\nResearch Question 1: How do liver enzyme levels (ALP, ALT, AST) change with age in people with hepatitis C compared to healthy individuals?\nThis research investigates how liver enzymes, which are important for diagnosing liver issues, vary as people get older, especially comparing those with hepatitis C to healthy people.\n\n\nData Preparation and Analysis\nData Preparation: - We used data from the hcvdat.csv dataset focusing on age and liver enzymes (ALP, ALT, AST). - We removed missing values and grouped data into age categories (‘Young’, ‘Middle-aged’, ‘Senior’) to analyze trends based on age.\nModel Training and Validation: - A Random Forest model was chosen for its robustness in handling datasets with multiple predictors. It was trained to predict log-transformed Albumin levels. - 10-fold cross-validation was used to validate the model, ensuring it performs well across different data subsets.\nModel Evaluation: - The model’s accuracy was assessed with Root Mean Square Error (RMSE) and R-squared values, where it scored an R-squared of 0.937. This means about 93.7% of the variability in Albumin levels was explained by the model. - The RMSE was 0.035, showing the model’s precision in predictions.\n\n\nVisualizations and Insights\nEnzyme Level Analysis by Age Group: - We made a bar plot to show average liver enzyme levels by age group, which helps us see changes in enzyme levels across ages, especially noting increases in older groups.\n\n\n\nEnzyme Level Analysis by Age Group\n\n\nModel Fit Visualization: - Residuals vs. Fitted Values Plot: Checked to ensure our model fits well. The plot showed residuals spread randomly, suggesting the model was appropriate without any clear misfit patterns.\n\n\n\nResiduals vs. Fitted Values Plot\n\n\n\n\nApproaches Considered and Rejected\nWe initially considered several methods: - Non-linear Models: These were tested for capturing complex relationships but not used due to the risk of making the model too complex. - Polynomial Regression: Was also considered to deal with curves in the data but was not used to keep the model simple and easy to interpret.\n\n\nReal-World Application\nThe findings are useful for: - Early Diagnosis: Better understanding of how liver enzymes change with age helps in spotting liver issues early. - Personalizing Treatment: Insights from the data can guide tailored treatments based on how enzyme levels change with age.\n\n\nConclusion\nThis study effectively used a Random Forest model to clarify how age impacts liver enzyme levels in hepatitis C patients compared to healthy individuals. It provided useful insights that could improve how liver conditions are managed.\n\n\nFuture Directions\nFurther research could improve these findings by: - Including more factors like broader demographic details and other health indicators to enhance predictions. - Conducting longitudinal studies to observe changes in enzyme levels over time, giving more insight into how liver diseases progress.\nThis webpage offers a detailed look at the research conducted, the methods used, the insights gained, and their practical implications, aiming to improve the management of liver health across different age groups.\n\n\n\nReferences\n\nUCI Machine Learning Repository: Hepatitis C Virus (HCV) Dataset. Available at: https://archive.ics.uci.edu/dataset/571/hcv+data. This link provides access to the dataset used in your analysis, essential for anyone looking to replicate or extend your research findings.\nProfessor’s Notes on ANOVA:\n\nUnit 3 and Unit 4 Notes: These documents are direct inputs from educational materials provided by your professor, covering detailed theoretical and practical applications of ANOVA, which underpin your analytical methodologies.\n\nBox, G. E. P., Hunter, J. S., & Hunter, W. G. (2005). Statistics for Experimenters: Design, Innovation, and Discovery (2nd Edition). Wiley. A foundational text on the principles of experimental design and analysis crucial for interpreting ANOVA results.\nMontgomery, D. C. (2017). Design and Analysis of Experiments (9th Edition). Wiley. Provides a comprehensive resource on experimental design and analysis, supporting the methodologies used in your analysis.\nNeter, J., Wasserman, W., & Kutner, M. H. (1996). Applied Linear Statistical Models (4th Edition). McGraw-Hill. Covers regression and analysis of variance in detail, supporting the statistical approaches and tests employed in your research."
  },
  {
    "objectID": "RQ3.html",
    "href": "RQ3.html",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "",
    "text": "In today’s world of personalized content, recommendation systems play a crucial role in enhancing user experiences. From Netflix suggesting your next favorite show to Amazon recommending products you’ll love, these systems rely on sophisticated algorithms to predict user preferences.\nThis project focuses on building a Movie Recommendation System using:\n1. K-Nearest Neighbors (KNN): Identifies similar users or movies to make predictions.\n2. Collaborative Filtering (CF): Leverages user-item interaction data to provide recommendations.\nThe MovieLens dataset was used as the foundation for this project, providing a robust collection of movie ratings from diverse users."
  },
  {
    "objectID": "Codes for Research Question 2.html",
    "href": "Codes for Research Question 2.html",
    "title": "Codes for Research Question 2",
    "section": "",
    "text": "Codes\nlibrary(tidyverse) library(car)\ndata_viable &lt;- read_csv(“hcvdat.csv”) %&gt;% mutate( Category = factor(Category, levels = c(“0=Blood Donor”, “1=Hepatitis”, “2=Fibrosis”, “3=Cirrhosis”)), Sex = factor(Sex, levels = c(“m”, “f”)), AgeGroup = cut(Age, breaks = c(0, 30, 50, 75, Inf), labels = c(“Young”, “Middle-aged”, “Senior”, “Elderly”)) )\nlevene_test_category &lt;- leveneTest(GGT ~ Category, data = data_viable) levene_test_sex &lt;- leveneTest(GGT ~ Sex, data = data_viable) levene_test_agegroup &lt;- leveneTest(GGT ~ AgeGroup, data = data_viable) levene_test_cat_sex &lt;- leveneTest(GGT ~ Category:Sex, data = data_viable)\nprint(levene_test_category) print(levene_test_sex) print(levene_test_agegroup) print(levene_test_cat_sex)\ndata_viable\\(log_GGT &lt;- log(data_viable\\)GGT + 1)\nanova_log_ggt &lt;- aov(log_GGT ~ Category * Sex * AgeGroup, data = data_viable) print(summary(anova_log_ggt))\nsimple_model &lt;- lm(log_GGT ~ Category + Sex + AgeGroup, data = data_viable) print(summary(simple_model))\np &lt;- ggplot(data_viable, aes(x = Category, y = log_GGT, color = Sex, shape = AgeGroup)) + geom_point(alpha = 0.6) + geom_smooth(method = “lm”, se = FALSE, fullrange = TRUE) + facet_wrap(~AgeGroup) + labs(title = “Interaction of Category, Sex, and Age on log(GGT) Levels”, y = “Log of Gamma-Glutamyl Transferase”, x = “Category”) + scale_color_brewer(palette = “Set1”) + theme_minimal()\nprint(p)"
  },
  {
    "objectID": "Codes for Research Question 1.html",
    "href": "Codes for Research Question 1.html",
    "title": "Codes for Research Question 1",
    "section": "",
    "text": "Codes\nlibrary(tidyverse) library(readr) library(caret) library(randomForest)\ndata &lt;- read_csv(“hcvdat.csv”) %&gt;% mutate( AgeGroup = cut(Age, breaks = c(0, 30, 50, Inf), labels = c(“Young”, “Middle-aged”, “Senior”)), Sex = factor(Sex, levels = c(“m”, “f”)), ALB_log = log(ALB + 1), Age2 = Age^2 ) %&gt;% na.omit()\nset.seed(123) train_indices &lt;- sample(1:nrow(data), 0.8 * nrow(data)) train_data &lt;- data[train_indices, ] validation_data &lt;- data[-train_indices, ]\nfitControl &lt;- trainControl(method = “cv”, number = 10, savePredictions = “final”) rf_model &lt;- train( ALB_log ~ Sex + Age + ALB + ALP + ALT + AST + BIL + CHE + CHOL + CREA + GGT + PROT + Age2, data = train_data, method = “rf”, ntree = 500, trControl = fitControl, importance = TRUE )\nprint(rf_model) varImpPlot(rf_model$finalModel, main = “Variable Importance”)\npredictions &lt;- predict(rf_model, newdata = validation_data) actuals &lt;- validation_data$ALB_log residuals &lt;- actuals - predictions RMSE &lt;- sqrt(mean(residuals^2)) R2 &lt;- cor(actuals, predictions)^2\nprint(paste(“RMSE:”, RMSE)) print(paste(“R-squared:”, R2))\nplot_data &lt;- data.frame(Fitted = predictions, Residuals = residuals) ggplot(plot_data, aes(x = Fitted, y = Residuals)) + geom_point() + geom_smooth(method = “lm”, se = TRUE, color = “blue”) + labs(title = “Residuals vs Fitted Values”, x = “Fitted Values”, y = “Residuals”)\ndata &lt;- data %&gt;% mutate(AgeGroup = cut(Age, breaks = c(0, 30, 50, 70), labels = c(“0-30”, “31-50”, “51-70”)))\nage_group_means &lt;- data %&gt;% group_by(AgeGroup) %&gt;% summarise( Mean_ALP = mean(ALP, na.rm = TRUE), Mean_ALT = mean(ALT, na.rm = TRUE), Mean_AST = mean(AST, na.rm = TRUE) )\nage_group_means %&gt;% gather(key = “Enzyme”, value = “Mean_Level”, -AgeGroup) %&gt;% ggplot(aes(x = AgeGroup, y = Mean_Level, fill = Enzyme)) + geom_bar(stat = “identity”, position = position_dodge()) + labs(title = “Average Liver Enzyme Levels by Age Group”, x = “Age Group”, y = “Average Enzyme Level”) + theme_minimal()"
  },
  {
    "objectID": "Codes for Research Question 3.html",
    "href": "Codes for Research Question 3.html",
    "title": "Codes for Research Question 3",
    "section": "",
    "text": "Codes\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(e1071)\nlibrary(nnet)\nlibrary(pROC)\nlibrary(randomForest)\ndata &lt;- read_csv(“hcvdat.csv”) %&gt;% mutate( Category = factor(Category, levels = c(“0=Blood Donor”, “1=Hepatitis”, “2=Fibrosis”, “3=Cirrhosis”), labels = c(“Blood_Donor”, “Hepatitis”, “Fibrosis”, “Cirrhosis”)), Sex = factor(Sex, levels = c(“m”, “f”)), log_ALB = log(ALB + 1), log_BIL = log(BIL + 1) ) %&gt;% na.omit()\nset.seed(123) training_indices &lt;- createDataPartition(data$Category, p = 0.8, list = FALSE) training_data &lt;- data[training_indices, ] test_data &lt;- data[-training_indices, ]\nfitControl &lt;- trainControl( method = “cv”, number = 10, summaryFunction = multiClassSummary, classProbs = TRUE, savePredictions = “final” )\nmodel_rf &lt;- train( Category ~ log_ALB + log_BIL + AST + ALT + GGT + Sex, data = training_data, method = “rf”, trControl = fitControl, metric = “Accuracy” )\nmodel_svm &lt;- train( Category ~ log_ALB + log_BIL + AST + ALT + GGT + Sex, data = training_data, method = “svmRadial”, trControl = fitControl, metric = “Accuracy” )\npredictions_rf &lt;- predict(model_rf, newdata = test_data) confusionMatrix_rf &lt;- confusionMatrix(predictions_rf, test_data\\(Category) probabilities_rf &lt;- predict(model_rf, newdata = test_data, type = \"prob\") roc_results_rf &lt;- lapply(levels(test_data\\)Category), function(class) roc(response = test_data$Category, predictor = probabilities_rf[, class])) aucs_rf &lt;- sapply(roc_results_rf, auc)\nprobabilities_svm &lt;- predict(model_svm, newdata = test_data, type = “prob”) roc_results_svm &lt;- lapply(levels(test_data\\(Category), function(class) roc(response = test_data\\)Category, predictor = probabilities_svm[, class])) aucs_svm &lt;- sapply(roc_results_svm, auc)\nprint(list(RandomForest_AUCs = aucs_rf, SVM_AUCs = aucs_svm))\nconfusionMatrix_rf &lt;- confusionMatrix(predictions_rf, test_data\\(Category) heatmap(as.matrix(confusionMatrix_rf\\)table), Rowv = NA, Colv = NA, scale = “column”, margins = c(5,5), xlab = “Predicted”, ylab = “Actual”, main = “Confusion Matrix Heatmap”)\nplot(roc_results_rf[[1]], col=“red”, main=“ROC Curves for Disease Categories”) for (i in 2:length(roc_results_rf)) { plot(roc_results_rf[[i]], add = TRUE, col=i) } legend(“bottomright”, legend=levels(test_data$Category), col=1:length(roc_results_rf), lwd=2)\nvarImpPlot(model_rf$finalModel, main = “Variable Importance in Predicting Liver Disease Severity”)"
  },
  {
    "objectID": "RQ2.html",
    "href": "RQ2.html",
    "title": "Research Question 2",
    "section": "",
    "text": "Research Question 2\n\nOverview\nResearch Question 2: Does gender influence biochemical responses in hepatitis C patients.\nThis question explores how biochemical markers, specifically Gamma-Glutamyl Transferase (GGT), respond differently in male and female hepatitis C patients. GGT is crucial for assessing liver health, and understanding its behavior can aid in more personalized healthcare.\n\n\nData Preparation and Analysis\nData Preparation: We started by refining our dataset to include only relevant variables such as gender, GGT levels, alongside age and hepatitis C status. We rigorously removed records with missing values to ensure the accuracy of our analysis.\nStatistical Analysis:\n- ANOVA and Multiple Regression Models: To assess the influence of gender on liver enzyme levels, we utilized these statistical methods. These models helped us quantify the differences and also explore potential interactions with age, which might modify how gender influences these biochemical markers. - Interaction Effects: We specifically looked for interaction effects between gender and other variables like age to understand if younger or older men and women showed different biochemical responses.\nVisualizations: We created several visual aids, including interaction plots and box plots, to visually represent the data. These visuals help illustrate any apparent differences or trends in how biochemical markers are influenced by gender across different age groups.\n\n\n\nInteraction of Category, Sex, and Age on log(GGT) Levels\n\n\nModel Evaluation:\n- Analysis Outcomes: The primary outputs of our analysis were the ANOVA tables, which provided p-values and F-statistics necessary to determine the significance of the observed differences. - Key Results: The ANOVA results indicated significant gender differences in biochemical responses, with F-statistic values suggesting robust model fit. For instance, the F value for the interaction between gender and age was 6.652 (p &lt; 0.0001), indicating significant interaction effects.\n\n\nApproaches Considered and Rejected\n\nLogistic Regression: Initially considered for its simplicity in handling binary outcomes, we ultimately did not use logistic regression because our focus was on continuous biochemical markers.\nComplex Multivariate Models: While potentially more robust, these models were deemed too complex for our current analysis scope, potentially complicating the interpretation without providing additional actionable insights.\n\n\n\nReal-World Application\n\nTailored Treatment Strategies: The insights derived from this analysis are crucial for developing tailored treatment strategies that consider gender differences, potentially improving outcomes for hepatitis C patients.\nEnhanced Disease Understanding: This research enhances our understanding of how hepatitis C interacts with biological differences between genders, which can be pivotal in advancing targeted therapy approaches.\n\n\n\nConclusion\nOur detailed analysis highlighted important differences in how male and female hepatitis C patients respond biochemically to the infection.\n\n\n\nReferences\n\nUCI Machine Learning Repository: Hepatitis C Virus (HCV) Dataset. Available at: https://archive.ics.uci.edu/dataset/571/hcv+data. This link provides access to the dataset used in your analysis, essential for anyone looking to replicate or extend your research findings.\nProfessor’s Notes on ANOVA:\n\nUnit 3 and Unit 4 Notes: These documents are direct inputs from educational materials provided by your professor, covering detailed theoretical and practical applications of ANOVA, which underpin your analytical methodologies.\n\nBox, G. E. P., Hunter, J. S., & Hunter, W. G. (2005). Statistics for Experimenters: Design, Innovation, and Discovery (2nd Edition). Wiley. A foundational text on the principles of experimental design and analysis crucial for interpreting ANOVA results.\nMontgomery, D. C. (2017). Design and Analysis of Experiments (9th Edition). Wiley. Provides a comprehensive resource on experimental design and analysis, supporting the methodologies used in your analysis.\nNeter, J., Wasserman, W., & Kutner, M. H. (1996). Applied Linear Statistical Models (4th Edition). McGraw-Hill. Covers regression and analysis of variance in detail, supporting the statistical approaches and tests employed in your research."
  },
  {
    "objectID": "Predictive Modeling for Hepatitis C.html",
    "href": "Predictive Modeling for Hepatitis C.html",
    "title": "Hepatitis C Data Analysis",
    "section": "",
    "text": "This webpage consolidates the detailed research conducted for three distinct research questions based on the Hepatitis C dataset. Each section retains the original formatting and content from the individual webpages.\n\n\n\n\n\nResearch Question 1: How do liver enzyme levels (ALP, ALT, AST) change with age in people with hepatitis C compared to healthy individuals?\nThis research investigates how liver enzymes, which are important for diagnosing liver issues, vary as people get older, especially comparing those with hepatitis C to healthy people.\n\n\n\nData Preparation\n- Focused on age and liver enzymes (ALP, ALT, AST) by removing missing values and grouping data into age categories (‘Young’, ‘Middle-aged’, ‘Senior’).\nModel Training and Validation\n- A Random Forest model with 10-fold cross-validation achieved: - R-squared: 0.937 (explaining 93.7% of variability in Albumin levels). - RMSE: 0.035 (high precision in predictions).\n\n\n\n\nEnzyme Level Analysis by Age Group\n\nResiduals vs. Fitted Values Plot\n\n\n\n\n\n\nNon-linear Models: Rejected due to the risk of overcomplication.\nPolynomial Regression: Avoided for simplicity and interpretability.\n\n\n\n\n\nEarly Diagnosis: Understanding enzyme changes aids in spotting liver issues early.\nPersonalized Treatment: Tailored treatments based on enzyme changes with age.\n\n\n\n\n\n\n\n\nResearch Question 2: Does gender influence biochemical responses in hepatitis C patients?\nThis question explores how Gamma-Glutamyl Transferase (GGT), an enzyme crucial for assessing liver health, varies between male and female hepatitis C patients.\n\n\n\nData Preparation\n- Focused on variables like gender, GGT levels, age, and hepatitis C status. - Removed missing values for accuracy.\nStatistical Analysis\n- ANOVA and Multiple Regression Models: Quantified gender differences and interactions with age. - Interaction Effects: Explored age and gender interaction on GGT levels.\n\n\n\n\nInteraction of Category, Sex, and Age on log(GGT) Levels\n\n\n\n\n\n\nTailored Treatment Strategies: Insights enable personalized treatments for males and females.\nEnhanced Disease Understanding: Improves understanding of gender-biased biochemical responses.\n\n\n\n\n\n\n\n\nResearch Question 3: How can we predict the severity of liver disease in patients?\nThe goal was to classify disease stages using biochemical markers and demographic data, aiding in early diagnosis and treatment.\n\n\n\nPredictive Modeling\n- Models: Random Forest and Multinomial Logistic Regression. - Validation: Cross-validation to prevent overfitting.\nEvaluation\n- AUC Scores: - Blood Donor: 0.99 - Hepatitis: 0.99 - Fibrosis: 0.99 - Cirrhosis: 0.82\n\n\n\n\nConfusion Matrix Heatmap\n\nROC Curves for Disease Categories\n\nVariable Importance Plot\n\n\n\n\n\n\nSupport for Clinical Decisions: Enhances diagnostic accuracy.\nManaging Healthcare Resources: Prioritizes care for severe cases.\n\n\n\n\n\n\nThe consolidated analysis across these research questions provides a comprehensive understanding of liver disease dynamics, enabling improved diagnostic and treatment methods.\n\n\n\n\n\nUCI Machine Learning Repository: Hepatitis C Virus (HCV) Dataset. Available at: https://archive.ics.uci.edu/dataset/571/hcv+data.\nProfessor’s Notes on ANOVA\n\nUnit 3 and Unit 4 Notes: Detailed theoretical and practical applications.\n\nBox, G. E. P., Hunter, J. S., & Hunter, W. G. (2005). Statistics for Experimenters. Wiley.\nMontgomery, D. C. (2017). Design and Analysis of Experiments. Wiley.\nNeter, J., Wasserman, W., & Kutner, M. H. (1996). Applied Linear Statistical Models. McGraw-Hill."
  },
  {
    "objectID": "India Performance Redesign.html#indias-cricket-world-cup-performance-redesign",
    "href": "India Performance Redesign.html#indias-cricket-world-cup-performance-redesign",
    "title": "Sports Performance Redesign: Cricket and NFL",
    "section": "",
    "text": "Venture into the vibrant history of India’s Cricket World Cup performances. This project reimagines India’s cricketing journey through innovative data visualizations, emphasizing clarity, engagement, and storytelling.\nThe redesign process aligns with three core objectives:\n1. Applying Analytical Skills: Leveraging classroom principles to improve visualization.\n2. Enhancing Interpretability: Transforming data into insightful narratives.\n3. Portfolio Building: Creating impactful visual stories that showcase analytical growth.\nStep into this exploration where every statistic has a tale, and every visualization unfolds a story of India’s cricketing excellence.\n\n\n\n\n\n\n\nTeam India’s Statistics throughout the World Cup\n\n\nThe original visualization depicts India’s World Cup performance from 1975 to 2011 using a stacked bar graph. However, it has notable shortcomings: - Clarity Issues: Wins and losses are layered atop the total matches, which can mislead viewers into interpreting them as additive figures. - Improvement Areas: Total matches played should serve as the foundation, with wins and losses proportionally segmented to accurately reflect India’s performance.\nThe redesign addresses these issues, ensuring a clearer and more accurate narrative of India’s cricketing history.\n\n\n\n\nThe redesigned visuals embrace interactivity and user-centric design. These visualizations provide layers of insights, allowing users to engage dynamically with India’s World Cup data.\n\nHighest and Lowest Scores: Explore India’s scoring highs and lows during World Cup matches through an interactive chart.\nMatch Outcomes: Examine India’s wins and losses year by year, enabling deeper trend analysis.\n\nEach visualization empowers users to uncover patterns and stories hidden within the data.\n\n\n\n\nRevamping India’s Cricket World Cup performance visualization underscores the intersection of statistical rigor and creative design. The redesign: - Clarifies India’s historical performance trends. - Enhances storytelling through dynamic visual engagement.\nFuture work could involve integrating alternative datasets or experimenting with advanced visualizations to further enrich the narrative."
  },
  {
    "objectID": "India Performance Redesign.html#nfl-super-bowl-wins-redesign-project",
    "href": "India Performance Redesign.html#nfl-super-bowl-wins-redesign-project",
    "title": "Sports Data Redesign Projects",
    "section": "",
    "text": "This project reimagines visualizations of NFL Super Bowl victories, analyzing success across teams, divisions, and conferences. By improving upon the original sunburst chart, the redesign focuses on clarity, accessibility, and storytelling.\n\n\n\n\n\n\n\nOriginal Sunburst Chart of NFL Super Bowl Wins\n\n\nThe original sunburst chart has several drawbacks: 1. Complexity vs. Utility: The radial layout obscures clarity and makes comparison difficult. 2. Design Preferences: Pie and sunburst charts distort data, violating best practices.\n\n\n\n\n\n\n\n\n\nRedesigned Dot Plot of NFL Team Wins\n\n\nThis dot plot provides clear, comparable data, categorizing teams by division and conference.\n\n\n\n\n\n\nInteractive Bar Plot Visualization\n\n\nThis interactive bar chart allows users to: 1. Filter by AFC or NFC to explore team victories across conferences. 2. Drill down to divisions for specific comparisons.\n\n\n\n\n\n\nClarity in Data Storytelling: Dot plots and bar charts make data more accessible.\nEngagement: Interactive elements encourage users to explore trends."
  },
  {
    "objectID": "India Performance Redesign.html#references",
    "href": "India Performance Redesign.html#references",
    "title": "Sports Data Redesign Projects",
    "section": "",
    "text": "ESPN Cricinfo Dataset. https://www.espncricinfo.com\nWickramasinghe, L. (2020). “Analyzing Cricket Performance Metrics.” Journal of Sports Analytics.\nChaturvedi, R. (2018). “Data-Driven Decisions in Cricket.” Data Science Quarterly.\n\n\n\n\n\nMcCann, Adam E. “Super Bowl Winners.” Tableau Public, Tableau Software, 2020. https://public.tableau.com."
  },
  {
    "objectID": "Bridge Longevity.html",
    "href": "Bridge Longevity.html",
    "title": "Optimizing Bridge Longevity Through Structural and Environmental Data Analysis",
    "section": "",
    "text": "Bridges are more than just structures—they are critical connectors, enabling transportation and economic growth. However, over time, they face significant challenges:\n1. Aging Materials: Decades of use degrade structural components, reducing their reliability.\n2. High Traffic Loads: Increased vehicular loads, especially in urban areas, accelerate wear and tear.\n3. Environmental Stress: Exposure to elements such as water, wind, and temperature fluctuations corrodes vital components.\n\n\nThis project aimed to uncover the factors contributing to bridge deterioration and predict their conditions using advanced data analytics and machine learning. By combining a robust dataset with cutting-edge algorithms, we sought to provide actionable insights to enhance maintenance strategies and improve the design of future infrastructure."
  },
  {
    "objectID": "Bridge Longevity.html#step-1-data-preprocessing",
    "href": "Bridge Longevity.html#step-1-data-preprocessing",
    "title": "Optimizing Bridge Longevity Through Structural and Environmental Data Analysis",
    "section": "3.1 Step 1: Data Preprocessing",
    "text": "3.1 Step 1: Data Preprocessing\nBefore delving into analytics, we cleaned and transformed the raw data:\n1. Handling Missing Values: Missing fields were imputed with median values to maintain consistency and avoid skewing results.\n2. Scaling and Normalization: Continuous features such as traffic volume were scaled to ensure all data was on a comparable scale.\n3. One-Hot Encoding: Categorical variables, such as material type, were converted into binary vectors for model compatibility."
  },
  {
    "objectID": "Bridge Longevity.html#step-2-exploratory-data-analysis-eda",
    "href": "Bridge Longevity.html#step-2-exploratory-data-analysis-eda",
    "title": "Optimizing Bridge Longevity Through Structural and Environmental Data Analysis",
    "section": "3.2 Step 2: Exploratory Data Analysis (EDA)",
    "text": "3.2 Step 2: Exploratory Data Analysis (EDA)\nEDA was critical in understanding the dataset’s structure and identifying key trends: - Traffic Analysis: High-traffic bridges showed significant wear, particularly in urban regions. - Age Trends: Older bridges exhibited higher deterioration rates. - Environmental Impact: Proximity to water bodies correlated strongly with substructure damage.\n\n\n\nHeatmap"
  },
  {
    "objectID": "Bridge Longevity.html#step-3-model-selection-and-training",
    "href": "Bridge Longevity.html#step-3-model-selection-and-training",
    "title": "Optimizing Bridge Longevity Through Structural and Environmental Data Analysis",
    "section": "3.3 Step 3: Model Selection and Training",
    "text": "3.3 Step 3: Model Selection and Training\n\n3.3.1 Machine Learning Models\nTo predict bridge conditions, we trained three machine learning models:\n1. Random Forest Classifier: Achieved 93% accuracy, excelling in feature importance and handling non-linear relationships.\n2. Decision Tree Classifier: Delivered 90% accuracy, with straightforward interpretability and lower computational cost.\n3. Logistic Regression: Provided 71% accuracy, limited by its linear nature but offering baseline insights.\n\n\n3.3.2 Training and Validation\n\nTraining Data: 80% of the dataset was used for training.\nValidation Data: 20% of the dataset was held out for testing.\nCross-Validation: We employed 5-fold cross-validation to ensure model robustness."
  },
  {
    "objectID": "Bridge Longevity.html#challenges-and-limitations",
    "href": "Bridge Longevity.html#challenges-and-limitations",
    "title": "Optimizing Bridge Longevity Through Structural and Environmental Data Analysis",
    "section": "7.1 Challenges and Limitations",
    "text": "7.1 Challenges and Limitations\n\nClass Imbalance: A significant portion of the dataset consisted of well-maintained bridges, which overshadowed the smaller sample of deteriorating structures. This imbalance required careful consideration during model training to avoid biased predictions.\nData Quality: Missing values and inconsistencies in the dataset presented challenges, necessitating rigorous preprocessing techniques to maintain accuracy and reliability."
  },
  {
    "objectID": "Bridge Longevity.html#practical-applications",
    "href": "Bridge Longevity.html#practical-applications",
    "title": "Optimizing Bridge Longevity Through Structural and Environmental Data Analysis",
    "section": "7.2 Practical Applications",
    "text": "7.2 Practical Applications\n\nMaintenance Prioritization: By leveraging predictive models, infrastructure agencies can identify high-risk bridges and allocate resources to maintain their safety and functionality.\nOptimized Design Strategies: Insights into the factors affecting bridge health—such as traffic volume and environmental conditions—can inform the construction of resilient bridges, particularly in high-risk areas."
  },
  {
    "objectID": "Bridge Longevity.html#summary-of-findings",
    "href": "Bridge Longevity.html#summary-of-findings",
    "title": "Optimizing Bridge Longevity Through Structural and Environmental Data Analysis",
    "section": "8.1 Summary of Findings",
    "text": "8.1 Summary of Findings\nThis study highlights the transformative power of big data and machine learning in addressing infrastructure challenges. By identifying critical predictors such as deck condition, traffic volume, and environmental exposure, we provided a roadmap for proactive bridge maintenance and design optimization.\n\n8.1.1 Key Takeaways\n\nRandom Forest was the most effective model, achieving 93% accuracy, with feature importance rankings that emphasized deck condition and traffic volume as the strongest predictors.\n\n\n\n\nModel Prediction and Performance\n\n\n\nBridges built before 1980 require immediate attention due to their advanced deterioration, highlighting the need for retrofitting and modernization."
  },
  {
    "objectID": "Bridge Longevity.html#looking-ahead",
    "href": "Bridge Longevity.html#looking-ahead",
    "title": "Optimizing Bridge Longevity Through Structural and Environmental Data Analysis",
    "section": "8.2 Looking Ahead",
    "text": "8.2 Looking Ahead\nThe journey to optimizing bridge longevity doesn’t end here. Future work could include: 1. Integrating real-time sensor data for continuous monitoring and early warning systems. 2. Exploring advanced algorithms such as Gradient Boosting and Neural Networks to further improve prediction accuracy. 3. Expanding the dataset to include weather patterns, regional traffic forecasts, and material-specific details for a more comprehensive analysis.\nBy incorporating these improvements, infrastructure agencies can ensure that bridges remain safe, functional, and resilient for generations to come."
  },
  {
    "objectID": "RQ3.html#dataset",
    "href": "RQ3.html#dataset",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "2.1 Dataset",
    "text": "2.1 Dataset\nThe dataset used for this project was sourced from the MovieLens platform. Key characteristics include: - User-Item Ratings: Numerical ratings assigned by users to movies. - Diversity: Wide range of movies across genres, enabling a comprehensive analysis. - Sparsity: Like most recommendation datasets, it is sparse, with many movies unrated by users."
  },
  {
    "objectID": "RQ3.html#techniques",
    "href": "RQ3.html#techniques",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "2.2 Techniques",
    "text": "2.2 Techniques\n\n2.2.1 K-Nearest Neighbors (KNN)\n\nSimilarity Metric: Euclidean distance was used to calculate similarity between users or movies.\nPrediction Methods:\n\nUnweighted KNN: Averages the ratings of the nearest neighbors.\nWeighted KNN: Applies a weight based on the distance of neighbors to provide more accurate predictions.\n\nParameter Testing: The number of neighbors (k) was varied (3, 5, 10) to evaluate the impact on prediction accuracy.\n\n\n\n2.2.2 Collaborative Filtering (CF)\n\nSimilarity Calculation: Cosine similarity was used to determine the closeness between movies based on user ratings.\nPrediction Method: A weighted average of ratings for similar movies was used to predict ratings for unrated movies.\nTrain-Test Splits: Evaluations were performed with train-test splits of 10%, 20%, 30%, and 40% to test the scalability and robustness of the model."
  },
  {
    "objectID": "RQ3.html#k-nearest-neighbors-knn-1",
    "href": "RQ3.html#k-nearest-neighbors-knn-1",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "3.1 K-Nearest Neighbors (KNN)",
    "text": "3.1 K-Nearest Neighbors (KNN)\nThe performance of KNN was evaluated using Root Mean Square Error (RMSE) across different k values:\n\n\n\nk Value\nRMSE (Unweighted)\nRMSE (Weighted)\n\n\n\n\n3\n0.655\n0.642\n\n\n5\n0.667\n0.654\n\n\n10\n0.672\n0.660\n\n\n\n\n3.1.1 Key Observations\n\nWeighted KNN consistently outperformed Unweighted KNN.\nSmaller values of k (e.g., k=3) provided slightly better accuracy, as larger neighborhoods introduced less relevant data."
  },
  {
    "objectID": "RQ3.html#performance-across-train-test-splits",
    "href": "RQ3.html#performance-across-train-test-splits",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "4.1 Performance Across Train-Test Splits",
    "text": "4.1 Performance Across Train-Test Splits\nCollaborative Filtering (CF) was evaluated using Root Mean Square Error (RMSE) across different train-test splits to assess its robustness and scalability. The results are summarized below:\n\n\n\nTest Set Size (%)\nRMSE\n\n\n\n\n10\n0.620\n\n\n20\n0.623\n\n\n30\n0.625\n\n\n40\n0.628\n\n\n\n\n4.1.1 Key Observations:\n\nConsistency: CF demonstrated stable performance with minimal RMSE variation across different train-test splits.\nScalability: The model’s consistent accuracy highlights its ability to handle varying dataset sizes effectively.\nComparison with KNN: CF outperformed KNN in RMSE, proving its suitability for large, sparse datasets like MovieLens.\n\n```{r, echo=FALSE, fig.align=“center”, out.width=“80%”} knitr::include_graphics(“CF_Accuracy.png”)"
  },
  {
    "objectID": "RQ3.html#summary-of-findings",
    "href": "RQ3.html#summary-of-findings",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "5.1 Summary of Findings",
    "text": "5.1 Summary of Findings\nThis project implemented a movie recommendation system using two distinct techniques:\n1. K-Nearest Neighbors (KNN): - Leveraged user similarity to predict ratings. - Weighted KNN outperformed unweighted, with smaller neighborhoods providing better accuracy.\n2. Collaborative Filtering (CF): - Utilized user-item interactions to predict preferences. - Demonstrated consistent accuracy across varying dataset sizes.\n\n5.1.1 Key Strengths\n\nCollaborative Filtering (CF):\n\nOutperformed KNN in both accuracy and scalability.\nRobust across different train-test splits, making it suitable for large datasets like MovieLens.\n\nKNN:\n\nProvided insights into how user similarity influences predictions, highlighting the role of neighborhood size."
  },
  {
    "objectID": "RQ3.html#conclusion-1",
    "href": "RQ3.html#conclusion-1",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "5.2 Conclusion",
    "text": "5.2 Conclusion\nThis project illustrated the strengths and limitations of KNN and CF techniques, offering a robust foundation for building recommendation systems. While CF emerged as the more scalable and accurate approach, KNN’s interpretability and simplicity remain valuable for specific applications."
  },
  {
    "objectID": "Movie Recommendation using KNN.html",
    "href": "Movie Recommendation using KNN.html",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "",
    "text": "In today’s world of personalized content, recommendation systems play a crucial role in enhancing user experiences. From Netflix suggesting your next favorite show to Amazon recommending products you’ll love, these systems rely on sophisticated algorithms to predict user preferences.\nThis project focuses on building a Movie Recommendation System using:\n1. K-Nearest Neighbors (KNN): Identifies similar users or movies to make predictions.\n2. Collaborative Filtering (CF): Leverages user-item interaction data to provide recommendations.\nThe MovieLens dataset was used as the foundation for this project, providing a robust collection of movie ratings from diverse users."
  },
  {
    "objectID": "Movie Recommendation using KNN.html#dataset",
    "href": "Movie Recommendation using KNN.html#dataset",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "2.1 Dataset",
    "text": "2.1 Dataset\nThe dataset used for this project was sourced from the MovieLens platform. Key characteristics include: - User-Item Ratings: Numerical ratings assigned by users to movies. - Diversity: Wide range of movies across genres, enabling a comprehensive analysis. - Sparsity: Like most recommendation datasets, it is sparse, with many movies unrated by users."
  },
  {
    "objectID": "Movie Recommendation using KNN.html#techniques",
    "href": "Movie Recommendation using KNN.html#techniques",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "2.2 Techniques",
    "text": "2.2 Techniques\n\n2.2.1 K-Nearest Neighbors (KNN)\n\nSimilarity Metric: Euclidean distance was used to calculate similarity between users or movies.\nPrediction Methods:\n\nUnweighted KNN: Averages the ratings of the nearest neighbors.\nWeighted KNN: Applies a weight based on the distance of neighbors to provide more accurate predictions.\n\nParameter Testing: The number of neighbors (k) was varied (3, 5, 10) to evaluate the impact on prediction accuracy.\n\n\n\n2.2.2 Collaborative Filtering (CF)\n\nSimilarity Calculation: Cosine similarity was used to determine the closeness between movies based on user ratings.\nPrediction Method: A weighted average of ratings for similar movies was used to predict ratings for unrated movies.\nTrain-Test Splits: Evaluations were performed with train-test splits of 10%, 20%, 30%, and 40% to test the scalability and robustness of the model."
  },
  {
    "objectID": "Movie Recommendation using KNN.html#k-nearest-neighbors-knn-1",
    "href": "Movie Recommendation using KNN.html#k-nearest-neighbors-knn-1",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "3.1 K-Nearest Neighbors (KNN)",
    "text": "3.1 K-Nearest Neighbors (KNN)\nThe performance of KNN was evaluated using Root Mean Square Error (RMSE) across different k values:\n\n\n\nk Value\nRMSE (Unweighted)\nRMSE (Weighted)\n\n\n\n\n3\n0.655\n0.642\n\n\n5\n0.667\n0.654\n\n\n10\n0.672\n0.660\n\n\n\n\n\n\nRMSE vs k value\n\n\n\n3.1.1 Key Observations\n\nWeighted KNN consistently outperformed Unweighted KNN.\nSmaller values of k (e.g., k=3) provided slightly better accuracy, as larger neighborhoods introduced less relevant data."
  },
  {
    "objectID": "Movie Recommendation using KNN.html#performance-across-train-test-splits",
    "href": "Movie Recommendation using KNN.html#performance-across-train-test-splits",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "4.1 Performance Across Train-Test Splits",
    "text": "4.1 Performance Across Train-Test Splits\nCollaborative Filtering (CF) was evaluated using Root Mean Square Error (RMSE) across different train-test splits to assess its robustness and scalability. The results are summarized below:\n\n\n\nTest Set Size (%)\nRMSE\n\n\n\n\n10\n0.620\n\n\n20\n0.623\n\n\n30\n0.625\n\n\n40\n0.628\n\n\n\n\n\n\nRMSE vs Test Set Size\n\n\n\n4.1.1 Key Observations:\n\nConsistency: CF demonstrated stable performance with minimal RMSE variation across different train-test splits.\nScalability: The model’s consistent accuracy highlights its ability to handle varying dataset sizes effectively.\nComparison with KNN: CF outperformed KNN in RMSE, proving its suitability for large, sparse datasets like MovieLens.\n\n\n\n\nComparison of KNN and CF Performance"
  },
  {
    "objectID": "Movie Recommendation using KNN.html#summary-of-findings",
    "href": "Movie Recommendation using KNN.html#summary-of-findings",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "5.1 Summary of Findings",
    "text": "5.1 Summary of Findings\nThis project implemented a movie recommendation system using two distinct techniques:\n1. K-Nearest Neighbors (KNN): - Leveraged user similarity to predict ratings. - Weighted KNN outperformed unweighted, with smaller neighborhoods providing better accuracy.\n2. Collaborative Filtering (CF): - Utilized user-item interactions to predict preferences. - Demonstrated consistent accuracy across varying dataset sizes.\n\n5.1.1 Key Strengths\n\nCollaborative Filtering (CF):\n\nOutperformed KNN in both accuracy and scalability.\nRobust across different train-test splits, making it suitable for large datasets like MovieLens.\n\nKNN:\n\nProvided insights into how user similarity influences predictions, highlighting the role of neighborhood size."
  },
  {
    "objectID": "Movie Recommendation using KNN.html#conclusion-1",
    "href": "Movie Recommendation using KNN.html#conclusion-1",
    "title": "Movie Recommendation System Using KNN and Collaborative Filtering",
    "section": "5.2 Conclusion",
    "text": "5.2 Conclusion\nThis project illustrated the strengths and limitations of KNN and CF techniques, offering a robust foundation for building recommendation systems. While CF emerged as the more scalable and accurate approach, KNN’s interpretability and simplicity remain valuable for specific applications."
  },
  {
    "objectID": "Predictive Modeling for Hepatitis C.html#research-question-1-age-and-liver-enzymes",
    "href": "Predictive Modeling for Hepatitis C.html#research-question-1-age-and-liver-enzymes",
    "title": "Hepatitis C Data Analysis",
    "section": "",
    "text": "Research Question 1: How do liver enzyme levels (ALP, ALT, AST) change with age in people with hepatitis C compared to healthy individuals?\nThis research investigates how liver enzymes, which are important for diagnosing liver issues, vary as people get older, especially comparing those with hepatitis C to healthy people.\n\n\n\nData Preparation\n- Focused on age and liver enzymes (ALP, ALT, AST) by removing missing values and grouping data into age categories (‘Young’, ‘Middle-aged’, ‘Senior’).\nModel Training and Validation\n- A Random Forest model with 10-fold cross-validation achieved: - R-squared: 0.937 (explaining 93.7% of variability in Albumin levels). - RMSE: 0.035 (high precision in predictions).\n\n\n\n\nEnzyme Level Analysis by Age Group\n\nResiduals vs. Fitted Values Plot\n\n\n\n\n\n\nNon-linear Models: Rejected due to the risk of overcomplication.\nPolynomial Regression: Avoided for simplicity and interpretability.\n\n\n\n\n\nEarly Diagnosis: Understanding enzyme changes aids in spotting liver issues early.\nPersonalized Treatment: Tailored treatments based on enzyme changes with age."
  },
  {
    "objectID": "Predictive Modeling for Hepatitis C.html#research-question-2-gender-influence-on-biochemical-responses",
    "href": "Predictive Modeling for Hepatitis C.html#research-question-2-gender-influence-on-biochemical-responses",
    "title": "Hepatitis C Data Analysis",
    "section": "",
    "text": "Research Question 2: Does gender influence biochemical responses in hepatitis C patients?\nThis question explores how Gamma-Glutamyl Transferase (GGT), an enzyme crucial for assessing liver health, varies between male and female hepatitis C patients.\n\n\n\nData Preparation\n- Focused on variables like gender, GGT levels, age, and hepatitis C status. - Removed missing values for accuracy.\nStatistical Analysis\n- ANOVA and Multiple Regression Models: Quantified gender differences and interactions with age. - Interaction Effects: Explored age and gender interaction on GGT levels.\n\n\n\n\nInteraction of Category, Sex, and Age on log(GGT) Levels\n\n\n\n\n\n\nTailored Treatment Strategies: Insights enable personalized treatments for males and females.\nEnhanced Disease Understanding: Improves understanding of gender-biased biochemical responses."
  },
  {
    "objectID": "Predictive Modeling for Hepatitis C.html#research-question-3-predicting-severity-of-liver-disease",
    "href": "Predictive Modeling for Hepatitis C.html#research-question-3-predicting-severity-of-liver-disease",
    "title": "Hepatitis C Data Analysis",
    "section": "",
    "text": "Research Question 3: How can we predict the severity of liver disease in patients?\nThe goal was to classify disease stages using biochemical markers and demographic data, aiding in early diagnosis and treatment.\n\n\n\nPredictive Modeling\n- Models: Random Forest and Multinomial Logistic Regression. - Validation: Cross-validation to prevent overfitting.\nEvaluation\n- AUC Scores: - Blood Donor: 0.99 - Hepatitis: 0.99 - Fibrosis: 0.99 - Cirrhosis: 0.82\n\n\n\n\nConfusion Matrix Heatmap\n\nROC Curves for Disease Categories\n\nVariable Importance Plot\n\n\n\n\n\n\nSupport for Clinical Decisions: Enhances diagnostic accuracy.\nManaging Healthcare Resources: Prioritizes care for severe cases."
  },
  {
    "objectID": "Predictive Modeling for Hepatitis C.html#conclusion",
    "href": "Predictive Modeling for Hepatitis C.html#conclusion",
    "title": "Hepatitis C Data Analysis",
    "section": "",
    "text": "The consolidated analysis across these research questions provides a comprehensive understanding of liver disease dynamics, enabling improved diagnostic and treatment methods."
  },
  {
    "objectID": "Predictive Modeling for Hepatitis C.html#references",
    "href": "Predictive Modeling for Hepatitis C.html#references",
    "title": "Hepatitis C Data Analysis",
    "section": "",
    "text": "UCI Machine Learning Repository: Hepatitis C Virus (HCV) Dataset. Available at: https://archive.ics.uci.edu/dataset/571/hcv+data.\nProfessor’s Notes on ANOVA\n\nUnit 3 and Unit 4 Notes: Detailed theoretical and practical applications.\n\nBox, G. E. P., Hunter, J. S., & Hunter, W. G. (2005). Statistics for Experimenters. Wiley.\nMontgomery, D. C. (2017). Design and Analysis of Experiments. Wiley.\nNeter, J., Wasserman, W., & Kutner, M. H. (1996). Applied Linear Statistical Models. McGraw-Hill."
  },
  {
    "objectID": "India Performance Redesign.html#indias-cricket-performance-redesign",
    "href": "India Performance Redesign.html#indias-cricket-performance-redesign",
    "title": "Sports Data Redesign Projects",
    "section": "",
    "text": "This project focuses on redesigning visualizations of India’s cricket team performance metrics, including wins, losses, and key player contributions. By improving the clarity and storytelling of the original visuals, we aim to offer insights that align with strategic decision-making in the sport.\n\n\n\n\n\n\n\nOriginal Cricket Performance Chart\n\n\nThe original visualization had the following drawbacks: 1. Overuse of Pie Charts: Difficult to compare percentages across multiple charts. 2. Data Overload: Too much data presented simultaneously, making it hard to identify patterns. 3. Lack of Narrative: The chart failed to tell a compelling story about India’s performance.\n\n\n\n\n\n\n   \nThe bar plot simplifies the data, allowing clear comparison between wins and losses over different years or tournaments.\n\n\n\n\n\n\nConsistency Over the Years: The bar plot reveals India’s consistent win ratio in bilateral series.\nTop Performers: The heatmap identifies players who made significant contributions in high-stakes matches."
  },
  {
    "objectID": "India Performance Redesign.html#conclusion",
    "href": "India Performance Redesign.html#conclusion",
    "title": "Sports Data Redesign Projects",
    "section": "",
    "text": "Both projects exemplify the power of redesigning sports data visualizations. By replacing complex and cluttered charts with clear, interactive visuals, these projects achieve: - Improved Analysis: Provides actionable insights into team performances. - Enhanced Engagement: Makes exploring sports data intuitive and informative.\nThese redesigns serve as a testament to the art of simplifying complexity and aligning visuals with academic rigor and storytelling."
  }
]